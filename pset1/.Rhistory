write_csv(product_data, file = "data_long.csv")
write_csv(product_data_long_blp, file = "data_BLPlong.csv")
data_long <- read.csv('data_long.csv')
### delete stuff
data_long <- data_long %>%
mutate(
branded = ifelse(brand_name == "Store Brand", 0, 1)
) %>%
select(week, store, product_brand, price, prom, income, mkt_share, branded)
data_clean_wide <- data_long %>%
pivot_wider(
names_from = product_brand,
values_from = price:branded
) %>%
na.omit()
write.csv(data_clean_wide, 'data_clean_wide.csv', row.names = FALSE)
View(data_clean_wide)
models_noIV <- feols(delta_log_share ~ price + prom | csw0(brand_name, brand_by_store),
data = product_data
)
models_costIV <- feols(delta_log_share ~ prom | csw0(brand_name, brand_by_store) |
price ~ cost,
data = product_data
)
models_hausIV <- feols(delta_log_share ~ prom | csw0(brand_name, brand_by_store) |
price ~ haus_iv,
data = product_data
)
models <- list(
models_noIV[[1]],
models_noIV[[2]],
models_noIV[[3]],
models_costIV[[1]],
models_costIV[[2]],
models_costIV[[3]],
models_hausIV[[1]],
models_hausIV[[2]],
models_hausIV[[3]]
)
x <- modelsummary(models,
output = "latex",
statistic = NULL,
stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01),
coef_omit = "Intercept",
gof_omit = "DF|Deviance|R2|AIC|BIC|RMSE|Std.Errors"
) %>%
add_header_above(c(" " = 1, "No IV" = 3, "Cost IV" = 3, "Hausman IV" = 3))
save_kable(x, "basic_models.tex")
## Calculating elasticities
# Getting price coefficients from each model
alpha <- models_noIV %>% map(~ .x$coefficients[[2]])
# getting mean price and market-shares (unweighted) by product
mean_price_share <- product_data %>%
group_by(product_brand) %>%
summarise(
mkt_share = mean(mkt_share),
price = mean(price)
)
own_price_elasticity <- mean_price_share %>%
ungroup() %>%
mutate(
model_1 = -alpha[[1]] * price * (1 - mkt_share),
model_2 = -alpha[[2]] * price * (1 - mkt_share),
model_3 = -alpha[[3]] * price * (1 - mkt_share)
) %>%
left_join(product_data %>%
ungroup() %>%
select(product_brand, brand_name, size) %>%
unique()) %>%
relocate(brand_name, size) %>%
select(-c(product_brand, mkt_share, price)) %>%
rename(
Brand = brand_name,
Size = size
)
y <- datasummary_df(own_price_elasticity, output = "latex") %>%
add_header_above(c(" " = 2, "Price elasticities" = 3))
save_kable(y, "elasticities_basic.tex")
library(haven)
dataforiv <- read_dta("C:/Users/arthu/Downloads/dataforiv.dta")
View(dataforiv)
View(dataforiv)
View(dataforiv)
library(tidyverse)
library(fixest)
library(modelsummary)
library(janitor)
library(kableExtra)
library(fastDummies)
# load data
OTC_instruments <- read.csv("OTCDataInstruments.csv", sep = "")
OTC_headache <- read.delim("~/GitHub/PhD_IO/pset1/OTC_Headache_upd.csv", header = TRUE)
store_dem <- read.csv("store_demographics.csv")
# Reshaping so that each row corresponds to a week-store-brand-size combination
product_data <- OTC_headache %>%
pivot_longer(sales_1:prom_11,
names_to = c(".value", "product-brand"),
names_pattern = "([A-Za-z]+)[^0-9]+([0-9]+)"
) %>%
left_join(store_dem, by = c("store" = "STORE")) %>%
clean_names() %>%
mutate(
product_brand = as.numeric(product_brand)
) %>%
# categorizing products, I assume 1-11 are in the same order as the table in
# question, and I've bundled all store brand objects as a single brand
mutate(
brand_name = case_when(
product_brand %in% 1:3 ~ "Tylenol",
product_brand %in% 4:6 ~ "Advil",
product_brand %in% 7:9 ~ "Bayer",
product_brand %in% 10:11 ~ "Store Brand"
),
size = case_when(
product_brand %in% c(1, 4, 7) ~ 25,
product_brand %in% c(2, 5, 8, 10) ~ 50,
product_brand %in% c(3, 6, 9, 11) ~ 100
)
) %>%
group_by(week) %>%
mutate(
haus_iv = (n() * mean(price) - price) / (n() - 1)
) %>%
group_by(week, store) %>%
# assumption - 2% of drug store customers go to it to by headache medicine
mutate(
mkt_share = sales / (0.02*count)
) %>%
mutate(
mkt_share_inside = sum(mkt_share),
mkt_share_outside = 1 - sum(mkt_share),
prom = ifelse(prom > 0, 1, prom)
# adjust promotion variable
) %>%
# creating brand-by-store dummy, this will make it easier than doing in estimation itself
mutate(
brand_by_store = paste(brand_name, "_", store),
delta_log_share = log(mkt_share) - log(mkt_share_outside)
) %>%
select(-c(count, sales, educ, hsizeavg, nwhite, mkt_share_inside, mkt_share_outside))
#adding iv vars, even the ones we wont use now (only in blp)
product_data <- product_data %>%
left_join(OTC_instruments %>%
rename(product_brand = brand) %>%
select(-cost_)) %>%
na.omit()
product_data_long_blp <- product_data %>%
# adding product dummies to just in case
dummy_cols(select_columns = "product_brand") %>%
dummy_cols(select_columns = "brand_name") %>%
select(-c(brand_by_store, brand_name, product_brand)) %>%
select(week, store, mkt_share, price, prom, starts_with('brand_'), cost, haus_iv, avoutprice,
starts_with('pricestore'), starts_with('product_brand')
)
write_csv(product_data, file = "data_long.csv")
write_csv(product_data_long_blp, file = "data_BLPlong.csv")
models_noIV <- feols(delta_log_share ~ price + prom | csw0(brand_name, brand_by_store),
data = product_data
)
models_costIV <- feols(delta_log_share ~ prom | csw0(brand_name, brand_by_store) |
price ~ cost,
data = product_data
)
models_hausIV <- feols(delta_log_share ~ prom | csw0(brand_name, brand_by_store) |
price ~ haus_iv,
data = product_data
)
models <- list(
models_noIV[[1]],
models_noIV[[2]],
models_noIV[[3]],
models_costIV[[1]],
models_costIV[[2]],
models_costIV[[3]],
models_hausIV[[1]],
models_hausIV[[2]],
models_hausIV[[3]]
)
x <- modelsummary(models,
output = "latex",
statistic = NULL,
stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01),
coef_omit = "Intercept",
gof_omit = "DF|Deviance|R2|AIC|BIC|RMSE|Std.Errors"
) %>%
add_header_above(c(" " = 1, "No IV" = 3, "Cost IV" = 3, "Hausman IV" = 3))
save_kable(x, "basic_models.tex")
## Calculating elasticities
# Getting price coefficients from each model
alpha <- models_noIV %>% map(~ .x$coefficients[[2]])
# getting mean price and market-shares (unweighted) by product
mean_price_share <- product_data %>%
group_by(product_brand) %>%
summarise(
mkt_share = mean(mkt_share),
price = mean(price)
)
own_price_elasticity <- mean_price_share %>%
ungroup() %>%
mutate(
model_1 = -alpha[[1]] * price * (1 - mkt_share),
model_2 = -alpha[[2]] * price * (1 - mkt_share),
model_3 = -alpha[[3]] * price * (1 - mkt_share)
) %>%
left_join(product_data %>%
ungroup() %>%
select(product_brand, brand_name, size) %>%
unique()) %>%
relocate(brand_name, size) %>%
select(-c(product_brand, mkt_share, price)) %>%
rename(
Brand = brand_name,
Size = size
)
y <- datasummary_df(own_price_elasticity, output = "latex") %>%
add_header_above(c(" " = 2, "Price elasticities" = 3))
save_kable(y, "elasticities_basic.tex")
data_long <- read.csv('data_long.csv')
### delete stuff
data_long <- data_long %>%
mutate(
branded = ifelse(brand_name == "Store Brand", 0, 1)
) %>%
select(week, store, product_brand, price, prom, income, mkt_share, branded)
data_clean_wide <- data_long %>%
pivot_wider(
names_from = product_brand,
values_from = price:branded
) %>%
na.omit()
write.csv(data_clean_wide, 'data_clean_wide.csv', row.names = FALSE)
View(data_long)
View(data_long)
OTC_instruments <- read.csv("OTCDataInstruments.csv", sep = "")
OTC_headache <- read.delim("~/GitHub/PhD_IO/pset1/OTC_Headache_upd.csv", header = TRUE)
store_dem <- read.csv("store_demographics.csv")
product_data <- OTC_headache %>%
pivot_longer(sales_1:prom_11,
names_to = c(".value", "product-brand"),
names_pattern = "([A-Za-z]+)[^0-9]+([0-9]+)"
) %>%
left_join(store_dem, by = c("store" = "STORE")) %>%
clean_names() %>%
mutate(
product_brand = as.numeric(product_brand)
) %>%
# categorizing products, I assume 1-11 are in the same order as the table in
# question, and I've bundled all store brand objects as a single brand
mutate(
brand_name = case_when(
product_brand %in% 1:3 ~ "Tylenol",
product_brand %in% 4:6 ~ "Advil",
product_brand %in% 7:9 ~ "Bayer",
product_brand %in% 10:11 ~ "Store Brand"
),
size = case_when(
product_brand %in% c(1, 4, 7) ~ 25,
product_brand %in% c(2, 5, 8, 10) ~ 50,
product_brand %in% c(3, 6, 9, 11) ~ 100
)
) %>%
group_by(week) %>%
mutate(
haus_iv = (n() * mean(price) - price) / (n() - 1)
) %>%
group_by(week, store) %>%
# assumption - 2% of drug store customers go to it to by headache medicine
mutate(
mkt_share = sales / (0.02*count)
) %>%
mutate(
mkt_share_inside = sum(mkt_share),
mkt_share_outside = 1 - sum(mkt_share),
prom = ifelse(prom > 0, 1, prom)
# adjust promotion variable
) %>%
# creating brand-by-store dummy, this will make it easier than doing in estimation itself
mutate(
brand_by_store = paste(brand_name, "_", store),
delta_log_share = log(mkt_share) - log(mkt_share_outside)
) %>%
select(-c(count, sales, educ, hsizeavg, nwhite, mkt_share_inside, mkt_share_outside))
#adding iv vars, even the ones we wont use now (only in blp)
product_data <- product_data %>%
left_join(OTC_instruments %>%
rename(product_brand = brand) %>%
select(-cost_)) %>%
na.omit()
product_data_long_blp <- product_data %>%
# adding product dummies to just in case
dummy_cols(select_columns = "product_brand") %>%
dummy_cols(select_columns = "brand_name") %>%
select(-c(brand_by_store, brand_name, product_brand)) %>%
select(week, store, mkt_share, price, prom, starts_with('brand_'), cost, haus_iv, avoutprice,
starts_with('pricestore'), starts_with('product_brand')
)
View(product_data_long_blp)
View(product_data_long_blp)
library(tidyverse)
set.seed(1)
a_L = 0.3
a_K = 0.2
a_M = 0.5
eta = -5
delta = 0.1
beta = 0.9
rho = 0.9
sigma_xi = 1
sigma_epsilon = 3
sigma_u = 2
p_k = 1
w = 1
N = 1000
t = 10
xi = matrix(0, N, t)
View(xi)
xi = matrix(rnorm(0, sigma_xi), N, t)
xi = matrix(rnorm(1, 0, sigma_xi), N, t)
View(xi)
a_L = 0.3
a_K = 0.2
a_M = 0.5
eta = -5
delta = 0.1
beta = 0.9
rho = 0.9
sigma_xi = 1
sigma_epsilon = 3
sigma_u = 2
p_k = 1
w = 1
N = 1000
t = 10
xi = matrix(rnorm(1, 0, sigma_xi), N, t)
?rnorm
xi = matrix(rnorm(N*t, sigma_xi), N, t)
View(xi)
omega = matrix(0, N, t)
omega[, 1] = xi[,1]
View(omega)
for i in 2:t{
for (i in 2:t) {
omega[,i] = rho*omega[, i-1] + xi[,i]
}
View(omega)
library(tidyverse)
library(gmm)
set.seed(2)
T_ = 10
I = 1000
# simulate productivity 50 periods past just to get stationarity
omega_past = matrix(0, I, 50)
for (t in 2:50){
omega_past[, t] = 0.9*omega_past[, t-1] + rnorm(1000, 0, 1)
}
xi = matrix(rnorm(I*T_, 0, 1), I, T_)
omega = matrix(0, I, T_)
omega[, 1] = 0.9*omega_past[, 50] + xi[, 1]
for (t in 2:T_){
omega[, t] = 0.9*omega[, t-1] + xi[, t]
}
epsilon = matrix(rnorm(I*T_, 0, 3), I, T_)
u = matrix(rnorm(I*T_, 0, 0.2), I, T_)
# capital and labor are determined one period in advance
L = matrix(0, I, T_)
L[, 1] = (0.108)^3*(0.73)^(0.8)*exp(3.69 + 3.6*omega_past[,50])
L[, 2:10] = (0.108)^3*(0.73)^(0.8)*exp(3.69 + 3.6*omega[,1:9])
K = 0.73*L
# materials are determined on the same period, and can be conditioned on epsilon
M = (0.4)^(5/3)*exp(8/75)*(exp(0.3*epsilon + omega)*L^(0.3)*K^(0.2))^(4/3)
# Realized revenue depends on the actual realizations of u
R = (exp(u + omega + 0.3*epsilon)*L^(0.3)*K^(0.2)*M^(0.5))^(0.8)
# Putting in long format
K = data.frame(K)
L = data.frame(L)
M = data.frame(M)
R = data.frame(R)
View(K)
dataset = list(K, L, M, R) %>%
map(~ .x %>%
mutate(i = n()))
rm(K, L, M, omega, omega_past, u, xi, t)
library(tidyverse)
library(gmm)
set.seed(2)
T_ = 10
I = 1000
# simulate productivity 50 periods past just to get stationarity
omega_past = matrix(0, I, 50)
for (t in 2:50){
omega_past[, t] = 0.9*omega_past[, t-1] + rnorm(1000, 0, 1)
}
xi = matrix(rnorm(I*T_, 0, 1), I, T_)
omega = matrix(0, I, T_)
omega[, 1] = 0.9*omega_past[, 50] + xi[, 1]
for (t in 2:T_){
omega[, t] = 0.9*omega[, t-1] + xi[, t]
}
epsilon = matrix(rnorm(I*T_, 0, 3), I, T_)
u = matrix(rnorm(I*T_, 0, 0.2), I, T_)
# capital and labor are determined one period in advance
L = matrix(0, I, T_)
L[, 1] = (0.108)^3*(0.73)^(0.8)*exp(3.69 + 3.6*omega_past[,50])
L[, 2:10] = (0.108)^3*(0.73)^(0.8)*exp(3.69 + 3.6*omega[,1:9])
K = 0.73*L
# materials are determined on the same period, and can be conditioned on epsilon
M = (0.4)^(5/3)*exp(8/75)*(exp(0.3*epsilon + omega)*L^(0.3)*K^(0.2))^(4/3)
# Realized revenue depends on the actual realizations of u
R = (exp(u + omega + 0.3*epsilon)*L^(0.3)*K^(0.2)*M^(0.5))^(0.8)
rm(epsilon, omega, omega_past, u, xi, t)
# Putting in long format
K = data.frame(K)
L = data.frame(L)
M = data.frame(M)
R = data.frame(R)
dataset = list(K, L, M, R) %>%
map(~ .x %>%
mutate(i = n()))
View(dataset)
View(dataset[[1]])
dataset = list(K, L, M, R) %>%
map(~ .x %>%
mutate(i = n()) %>%
relocate(i))
View(dataset[[1]])
dataset = list(K = K, L = L, M = M, R = R) %>%
map(~ .x %>%
mutate(i = n()) %>%
relocate(i))
View(dataset)
View(dataset[["K"]])
dataset = list(K = K, L = L, M = M, R = R) %>%
map(~ .x %>%
mutate(i = row_number()) %>%
relocate(i))
View(dataset[["K"]])
l2 = list('K', 'L', 'M', 'R')
l1 = list(K = K, L = L, M = M, R = R)
dataset <-
map2(l1, l2, ~ l1 %>%
mutate(i = row_number()) %>%
relocate(i) %>%
pivot_longer(X1:X10, names_to = "t",
values_to = l2))
dataset <-
map2(l1, l2, ~ .x %>%
mutate(i = row_number()) %>%
relocate(i) %>%
pivot_longer(X1:X10, names_to = "t",
values_to = .y))
View(dataset)
View(dataset[["K"]])
?pivot_longer
dataset <-
map2(l1, l2, ~ .x %>%
mutate(i = row_number()) %>%
relocate(i) %>%
pivot_longer(X1:X10, names_to = "t",
values_to = .y) %>%
mutate(t = substr(x, 2, -1)))
dataset <-
map2(l1, l2, ~ .x %>%
mutate(i = row_number()) %>%
relocate(i) %>%
pivot_longer(X1:X10, names_to = "t",
values_to = .y) %>%
mutate(t = substr(t, 2, -1)))
View(dataset)
View(dataset[["K"]])
dataset <-
map2(l1, l2, ~ .x %>%
mutate(i = row_number()) %>%
relocate(i) %>%
pivot_longer(X1:X10, names_to = "t",
values_to = .y) %>%
mutate(t = substr(t, 2, nchar(t))))
View(dataset)
View(dataset[["K"]])
dataset <-
map2(l1, l2, ~ .x %>%
mutate(i = row_number()) %>%
relocate(i) %>%
pivot_longer(X1:X10, names_to = "t",
values_to = .y) %>%
mutate(t = substr(t, 2, nchar(t)) %>%
as.numeric()))
View(dataset)
View(dataset[["K"]])
View(dataset[["L"]])
data_long = cbind(dataset$K,
dataset$L[, 3],
dataset$M[,3],
dataset$R[, 3])
View(data_long)
View(data_long)
# getting lagged inputs
data_long <- data_long %>%
group_by(i) %>%
arrange(t) %>%
mutate(L_lag = lag(L, 1),
K_lag = lag(K, 1),
M_lag = lag(M, 1))
View(data_long)
# getting lagged inputs
data_long <- data_long %>%
group_by(i) %>%
arrange(t) %>%
mutate(L_lag = lag(L, 1),
K_lag = lag(K, 1),
M_lag = lag(M, 1)) %>%
na.omit()
View(data_long)
